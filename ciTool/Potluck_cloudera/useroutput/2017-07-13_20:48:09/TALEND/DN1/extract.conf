#
# All directories must end in trailing slash (/). This is assumed by the
# Talend job.
#

[source]

# HDFS URI - hdfs://<hadoop-nameservice>:<port>
source_uri = hdfs://mrx

# Input file glob exprssion
source_file_mask = *.gz

# Kafka broker comma separated URI list - <broker1:port1>,<broker2:port2>...
kafka_uri = 192.168.115.234:9092

# Zookeeper comma separated URI list - # <zookeeper1:port1>,<zookeeper2:port2>...
zookeeper_list=192.168.115.234:2181

# Schema registry server.
#registry_url = http://<loadbalancer-VIP>:8081
registry_url = http://192.168.115.241:8081

# Kafka topic name to white the ingestion job will write
kafka_topic_http = gauvus_http
kafka_topic_nonhttp =  guavus_nonhttp

#
# Top-level directory under which the following sub-directories are expected
# to be present:
#
#   - input   Directory containing input files.
#   - ready   Directory containing files that have been ingested.
#   - produce Directory containing files presently being read.
#
root_dir = /user/mrx/globe/

# Directory on the local filesystem for temporary files
tmp_dir = /tmp/mrx/

# Maximum number of files that will be sent to the Kafka topic in parallel
parallel_degree = 24

# Type of input. Possible values: radcom, cisco, cisco_edrflow, guavus
vendor = guavus

# high availibility configuration
ha_nameservices_property        = dfs.nameservices
ha_namenodes_property           = dfs.ha.namenodes.mrx
ha_namenode_1_property          = dfs.namenode.rpc-address.mrx.marx4.ggn.in.guavus.com
ha_namenode_2_property          = dfs.namenode.rpc-address.mrx.marx5.ggn.in.guavus.com
ha_failover_proxy_property      = dfs.client.failover.proxy.provider.mrx

ha_nameservices                 = mrx
ha_namenodes                    = marx4.ggn.in.guavus.com,marx5.ggn.in.guavus.com
ha_namenode_1                   = marx4.ggn.in.guavus.com:8020
ha_namenode_2                   = marx5.ggn.in.guavus.com:8020
ha_failover_proxy               = org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
